<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Evaluating mathematical reasoning of foundation models in visual contexts">
  <meta name="keywords" content="MathVista, Math Vista">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
/Users/panlu/Library/Mobile Documents/com~apple~CloudDocs/ImageMath/visual-mathqa-server/data_final/images
    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link rel="icon" href="./static/images/mathvista.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-1 publication-title is-bold">
            <!-- <img src="static/images/mathvista.png" style="width:1em;vertical-align: middle" alt="Logo"/> -->
            <span class="mathvista" style="vertical-align: middle">BlenderGym</span>
          </h2>
          <h3>
            The First VLM System Benchmark for 3D Graphics.
          </h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://richard-guyunqi.github.io/">Yunqi Gu</a><sup>1</sup>,
            </span>
              <a href="https://ianhuang.ai/">Ian Huang</a><sup>1</sup>,
            </span>     
              <a href="https://jihyeonje.com/">Jihyeon Je</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.guandaoyang.com/">Guandao Yang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Stanford University</span><br>
            <span class="paper-block"><b>CVPR 2025</b></span>
          </div>
        
          <!-- <section> -->
            <!-- <div class="section" id="org-banners" style="display:fle">
              <a href="https://www.ucla.edu/" target="_blank" rel="external">
                  <img class="center-block org-banner" src="static/images/ucla.png" style="height:3em">
              </a>
              <a href="https://www.washington.edu/" target="blank" class="ext-link">
                  <img class="center-block org-banner" src="static/images/uw.png" style="height:3em">
              </a>
              <a href="https://www.microsoft.com/en-us/research/" target="_blank" rel="external">
                  <img class="center-block org-banner" src="static/images/microsoft.png" style="height:3em">
              </a>
            </div> -->
          <!-- </section> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org/pdf/2310.02255.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.02255"
                   class="external-link button is-normal is-rounded is-dark">
                <!-- <a href="https://lupantech.github.io/papers/arxiv23_mathvista.pdf"
                   class="external-link button is-normal is-rounded is-dark"> -->
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/lupantech/MathVista"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/AI4Math/MathVista"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ü§ó</p>
                      <!-- üîó -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="https://mathvista.github.io/#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">üèÜ</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>
              <!-- Twitter Link. -->
              <span class="link-block">
                <a href="https://twitter.com/lupantech/status/1717313355780964608"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <!-- üíªüîó -->
                      <p style="font-size:18px">üåê</p>
                  </span>
                  <span>Twitter</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
      <img src="static/images/tease_scores_gpt4v.png" alt="geometric reasoning" width="99%"/>
      <p> Accuracy scores of one leading LLM (i.e., PoT GPT-4), four primary LMMs, random chance, and human performance our proposed 
      <img src="static/images/mathvista.png" style="width:1.0em;vertical-align: middle" alt="Logo"/>
      <span class="mathvista">MathVista</span>
      across mathematical reasoning and visual context types. PoT refers to program-of-thought prompting, and PoT GPT-4 is a textual LLM augmented with the caption and OCR text. GPT-4V is manually evaluated via the playground chatbot.
      </p>
    </div>
  </div>
</section> -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/tea.png" alt="Teaser Image" style="width:100%;">
      <h2 class="subtitle has-text-centered" style="font-size: 18px;"> 
        BlenderGym, a 3D graphics benchmark that tasks VLMs with 3D scene reconstruction through code editing. BlenderGym consists of 245 handcrafted start-goal scene pairs across five key graphics editing tasks: object placement, lighting adjustment, procedural material editing, blend shape manipulation, and procedural geometry editing.      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            3D graphics editing is a crucial component in applications like movie production and game design, yet it remains a time-consuming process that demands highly specialized domain expertise. Automating the process is challenging because graphical editing requires performing a variety of tasks, each requiring distinct skill sets. Recently, vision-language models (VLMs) have emerged as a powerful framework for automating the editing process, but their development and evaluation are bottlenecked by the lack of a comprehensive benchmark that requires human-level perception and presents real-world editing complexity. 
          </p>
          <p>
            In this work, we present <b>BlenderGym</b>, a comprehensive VLM system benchmark for 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3D reconstruction tasks. We evaluate closed- and open-source VLM systems and observe that even the state-of-the-art VLM system struggles with tasks relatively easy for human Blender users. 
          </p>
          <p>
            Enabled by BlenderGym, we study how <b>inference scaling on verification</b> impacts VLM's performance on graphics editing tasks. Notably, our findings reveal that the verifier used to guide the scaling of generation can itself be improved through inference scaling, complementing recent insights on inference scaling of LLM generation in coding and math tasks. We further show that inference compute is not uniformly effective and can be optimized by strategically distributing it between generation and verification. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="hero-body">
          <img src="./static/images/overview.png" alt="Overview Image" style="width:100%;">
          <h2 class="subtitle has-text-centered" style="font-size: 16px;"> 
            Examples of task instances and VLM system output edits. We present start scene, goal scene, human user edit, and VLM system edits side by side with their corresponding metric values.
        </div>  
        <div class="content has-text-justified">
          <p>
            We aim to enable comprehensive comparison and analysis of VLM systems on 3D graphics editing tasks, which is currently bottlenecked by (1) the incomprehensive coverage of task settings with current evaluation approaches and (2) the absence of robust metrics due to unscalability of human evaluation and unreliability of AI-judge. 
          </p>
          <p>
            To overcome these two challenges, we introduce BlenderGym‚Äîthe first VLM systems benchmark tailored to 3D graphics. BlenderGym features in (1) the comprehensive coverage of essential graphics editing tasks with support for a wide range of VLM systems, (2) quantitative evaluation with image and 3D metrics, eliminating the need for human or AI-based evaluations and (3) support for inference time scaling experiments on graphics editing tasks.
          </p>
          <p>
            BlenderGym consists of 245 hand-crafted Blender scenes across 5 key graphics editing tasks: procedural geometry editing, lighting adjustments, procedural material design, blend shape manipulation, and object placement (45/30/30/65/30 instances respectively). Each instance in BlenderGym presents a reconstruction task from a start scene to a goal scene, where the start scene serves as the original input for the VLM system, and the goal scene represents the desired output state that the VLM system is tasked with reconstructing. Each start-goal instance includes a base Blender file of the scene setup, a pair of Python scripts that generate the start and goal scene, rendered images for both scenes, and language description of the differences between the two scenes. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<section class="section">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">

        <h2 class="title is-3" id="leaderboard_test">Leaderboard</h2>
        <div class="content">

        <table class="js-sort-table" id="results">
          <tr>
              <td rowspan="2"><strong>#</strong></td>
              <td rowspan="2"><strong>Model</strong></td>
              <td rowspan="2"><strong>Source</strong></td>
              <td rowspan="2"><strong>Date</strong></td>
              <td colspan="3"><strong>Blend Shape</strong></td>
              <td colspan="3"><strong>Placement</strong></td>
              <td colspan="3"><strong>Geometry</strong></td>
              <td colspan="2"><strong>Lighting</strong></td>
              <td colspan="2"><strong>Material</strong></td>
          </tr>
          <tr>
              <!-- Blend Shape -->
              <td><strong>PL</strong></td>
              <td style="white-space: nowrap;"><strong>N-CLIP</strong></td>
              <td><strong>CD</strong></td>
      
              <!-- Placement -->
              <td><strong>PL</strong></td>
              <td style="white-space: nowrap;"><strong>N-CLIP</strong></td>
              <td><strong>CD</strong></td>
      
              <!-- Geometry -->
              <td><strong>PL</strong></td>
              <td style="white-space: nowrap;"><strong>N-CLIP</strong></td>
              <td><strong>CD</strong></td>
      
              <!-- Lighting -->
              <td><strong>PL</strong></td>
              <td style="white-space: nowrap;"><strong>N-CLIP</strong></td>
      
              <!-- Material -->
              <td><strong>PL</strong></td>
              <td style="white-space: nowrap;"><strong>N-CLIP</strong></td>
          </tr>
      
          <!-- 1. GPT-4o -->
          <tr>
              <td>1</td>
              <td>GPT-4o</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td><b>9.140</b></td>
              <td><b>20.47</b></td>
              <td><b>0.904</b></td>
              <!-- Placement -->
              <td>11.89</td>
              <td><b>30.38</b></td>
              <td>11.22</td>
              <!-- Geometry -->
              <td><b>6.747</b></td>
              <td>8.561</td>
              <td>1.192</td>
              <!-- Lighting -->
              <td><b>2.410</b></td>
              <td>2.398</td>
              <!-- Material -->
              <td><b>3.653</b></td>
              <td>8.942</td>
          </tr>
      
          <!-- 2. Claude-3.5-Sonnet -->
          <tr>
              <td>2</td>
              <td>Claude-3.5-Sonnet</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>12.79</td>
              <td>27.96</td>
              <td>1.962</td>
              <!-- Placement -->
              <td>13.19</td>
              <td>51.76</td>
              <td>11.29</td>
              <!-- Geometry -->
              <td>10.81</td>
              <td>13.04</td>
              <td>1.452</td>
              <!-- Lighting -->
              <td>2.897</td>
              <td>4.049</td>
              <!-- Material -->
              <td>5.769</td>
              <td>11.44</td>
          </tr>
      
          <!-- 3. GPT-4-Turbo -->
          <tr>
              <td>3</td>
              <td>GPT-4-Turbo</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>15.21</td>
              <td>26.15</td>
              <td>1.927</td>
              <!-- Placement -->
              <td>12.21</td>
              <td>37.57</td>
              <td>12.80</td>
              <!-- Geometry -->
              <td>8.160</td>
              <td>10.92</td>
              <td><b>1.120</b></td>
              <!-- Lighting -->
              <td>2.723</td>
              <td>3.912</td>
              <!-- Material -->
              <td>5.424</td>
              <td><b>8.812</b></td>
          </tr>
      
          <!-- 4. Claude-3-Haiku -->
          <tr>
              <td>4</td>
              <td>Claude-3-Haiku</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>13.62</td>
              <td>29.72</td>
              <td>2.563</td>
              <!-- Placement -->
              <td>14.78</td>
              <td>44.10</td>
              <td>12.13</td>
              <!-- Geometry -->
              <td>10.15</td>
              <td>12.51</td>
              <td>1.362</td>
              <!-- Lighting -->
              <td>3.712</td>
              <td>4.824</td>
              <!-- Material -->
              <td>5.960</td>
              <td>11.61</td>
          </tr>
      
          <!-- 5. Gemini-1.5-flash -->
          <tr>
              <td>5</td>
              <td>Gemini-1.5-flash</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>23.18</td>
              <td>30.47</td>
              <td>2.412</td>
              <!-- Placement -->
              <td><b>10.94</b></td>
              <td>45.34</td>
              <td><b>8.324</b></td>
              <!-- Geometry -->
              <td>9.443</td>
              <td>10.49</td>
              <td>1.323</td>
              <!-- Lighting -->
              <td>3.514</td>
              <td>5.688</td>
              <!-- Material -->
              <td>6.364</td>
              <td>10.42</td>
          </tr>
      
          <!-- 6. Qwen2-vl-7b -->
          <tr>
              <td>6</td>
              <td>Qwen2-vl-7b</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>16.78</td>
              <td>29.22</td>
              <td>2.123</td>
              <!-- Placement -->
              <td>15.31</td>
              <td>41.12</td>
              <td>14.21</td>
              <!-- Geometry -->
              <td>--</td>
              <td>--</td>
              <td>--</td>
              <!-- Lighting -->
              <td>2.985</td>
              <td><b>2.225</b></td>
              <!-- Material -->
              <td>--</td>
              <td>--</td>
          </tr>
      
          <!-- 7. Qwen-Llama -->
          <tr>
              <td>7</td>
              <td>Qwen-Llama</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>14.32</td>
              <td>28.23</td>
              <td>2.012</td>
              <!-- Placement -->
              <td>14.65</td>
              <td>34.93</td>
              <td>12.41</td>
              <!-- Geometry -->
              <td>13.97</td>
              <td>14.13</td>
              <td>1.673</td>
              <!-- Lighting -->
              <td>3.173</td>
              <td>3.998</td>
              <!-- Material -->
              <td>--</td>
              <td>--</td>
          </tr>
      
          <!-- 8. Phi-3.5-vision -->
          <tr>
              <td>8</td>
              <td>Phi-3.5-vision</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>12.51</td>
              <td>24.14</td>
              <td>2.012</td>
              <!-- Placement -->
              <td>--</td>
              <td>--</td>
              <td>--</td>
              <!-- Geometry -->
              <td>--</td>
              <td>--</td>
              <td>--</td>
              <!-- Lighting -->
              <td>3.127</td>
              <td>6.012</td>
              <!-- Material -->
              <td>--</td>
              <td>--</td>
          </tr>
      
          <!-- 9. Phi-Llama -->
          <tr>
              <td>9</td>
              <td>Phi-Llama</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>12.13</td>
              <td>24.77</td>
              <td>1.826</td>
              <!-- Placement -->
              <td>14.61</td>
              <td>35.61</td>
              <td>12.61</td>
              <!-- Geometry -->
              <td>9.818</td>
              <td>11.92</td>
              <td>1.471</td>
              <!-- Lighting -->
              <td>3.621</td>
              <td>6.895</td>
              <!-- Material -->
              <td>--</td>
              <td>--</td>
          </tr>
      
          <!-- 10. MiniCPM-V-2.6 -->
          <tr>
              <td>10</td>
              <td>MiniCPM-V-2.6</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>13.86</td>
              <td>29.92</td>
              <td>1.997</td>
              <!-- Placement -->
              <td>11.99</td>
              <td>31.69</td>
              <td>12.62</td>
              <!-- Geometry -->
              <td>7.127</td>
              <td><b>8.542</b></td>
              <td>1.229</td>
              <!-- Lighting -->
              <td>3.829</td>
              <td>6.124</td>
              <!-- Material -->
              <td>--</td>
              <td>--</td>
          </tr>
      
          <!-- 11. MiniCPM-Llama -->
          <tr>
              <td>11</td>
              <td>MiniCPM-Llama</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>13.76</td>
              <td>27.21</td>
              <td>1.882</td>
              <!-- Placement -->
              <td>12.74</td>
              <td>31.72</td>
              <td>15.81</td>
              <!-- Geometry -->
              <td>9.561</td>
              <td>11.47</td>
              <td>1.569</td>
              <!-- Lighting -->
              <td>3.725</td>
              <td>6.090</td>
              <!-- Material -->
              <td>7.152</td>
              <td>12.14</td>
          </tr>
      
          <!-- 12. InternVL2-8b -->
          <tr>
              <td>12</td>
              <td>InternVL2-8b</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>12.69</td>
              <td>29.09</td>
              <td>1.920</td>
              <!-- Placement -->
              <td>14.71</td>
              <td>35.92</td>
              <td>17.22</td>
              <!-- Geometry -->
              <td>--</td>
              <td>--</td>
              <td>--</td>
              <!-- Lighting -->
              <td>3.920</td>
              <td>6.825</td>
              <!-- Material -->
              <td>--</td>
              <td>--</td>
          </tr>
      
          <!-- 13. Intern-Llama -->
          <tr>
              <td>13</td>
              <td>Intern-Llama</td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td>11.80</td>
              <td>23.83</td>
              <td>1.861</td>
              <!-- Placement -->
              <td>16.15</td>
              <td>37.23</td>
              <td>18.22</td>
              <!-- Geometry -->
              <td>13.70</td>
              <td>14.44</td>
              <td>1.578</td>
              <!-- Lighting -->
              <td>3.825</td>
              <td>6.152</td>
              <!-- Material -->
              <td>--</td>
              <td>--</td>
          </tr>
      
          <!-- 14. Human -->
          <tr>
              <td> </td>
              <td><b>Human</b></td>
              <td>N/A</td>
              <td>N/A</td>
              <!-- Blend Shape -->
              <td><b>0.934</b></td>
              <td><b>9.12</b></td>
              <td><b>0.399</b></td>
              <!-- Placement -->
              <td><b>0.423</b></td>
              <td><b>13.34</b></td>
              <td><b>1.532</b></td>
              <!-- Geometry -->
              <td><b>1.269</b></td>
              <td><b>2.434</b></td>
              <td><b>0.334</b></td>
              <!-- Lighting -->
              <td><b>1.239</b></td>
              <td><b>1.632</b></td>
              <!-- Material -->
              <td><b>0.629</b></td>
              <td><b>3.043</b></td>
          </tr>
      </table>
          <br>
          <div>
          <p>üö® To submit your results to the leaderboard, please send to <a href="yrichard@stanford.edu">this email</a> with your result json files.</p>
          <p>üö® For more submission details, please refer to <a href="https://github.com/lupantech/MathVista?tab=readme-ov-file#-leaderboard-">this link</a>.
          </p>
          </div>
        </div>

      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Verifier Scaling</h2>
        <div class="content has-text-justified">
          <p>
          To complement recent findings on inference scaling of VLM/LLM generation, we explore improving the verifier that guides the generation by selecting desirable edits and pruning suboptimal ones. 
          </p>

          <figure>
            <div class="columns is-centered" style="align-items: center;">
              <!-- First Image Column, smaller width -->
              <div class="column" style="flex: 0 40% 40%;">
                <figure class="image">
                  <img src="./static/images/veri_scaling.png" alt="Verifier scaling figure" style="width: 100%; height: auto; object-fit: contain;">
                  <figcaption style="font-size: 13px; text-align: center;">Verifier scaling results with InternVL2-8B, Claude3.5 Sonnet, and GPT4o. Increasing verifier queries brings the selected edit closer to the goal. VLMs used as verifiers to guide generation could also benefit from inference scaling.</figcaption>
                </figure>
              </div>
          
              <!-- Second Image Column, larger width but same height -->
              <div class="column" style="flex: 0 0 60%; margin-top:0px">
                <figure class="image">
                  <img src="./static/images/allocation_compute.png" alt="Allocation of compute figure" style="width: 100%; height: auto; object-fit: contain;">
                  <figcaption style="font-size: 13px; text-align: center;">The impact of compute allocation on VLM system performance. We set VeriRatios to 0.33, 0.62, and 0.73. We observe that when more compute is available, a higher share of verification yields greater benefits.</figcaption>
                </figure>
              </div>
            </div>
          </figure>

          <p>
          We find that similar to generation, VLM verifiers used for guiding generation also benefit from inference scaling, and that scaled open-source VLM verifiers can exceed the performance of closed-source VLM verifiers.
          </p>
          <p>
          With that knowledge, we further explore the question of distributing inference compute between generation and verification. We find that (1) the distribution of inference compute significantly impacts performance, and that (2) the optimal compute ratio between generation and verification varies with the amount of total compute ‚Äî more total compute benefits from a higher share of verification.
          </p>
        </div>
    </div>
  </div>
  <br>
</section>

<section class="section no-spacing">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-6">Acknowledgements</h2>
        <div class="content has-text-justified">
            We acknowledge the support of ARL grant W911NF-21-2-0104 and a Vannevar Bush Faculty Fellowship. Additionally, We would like to thank Yangjun Ruan, Haiwen (Haven) Feng, Jordan Juravsky, and all our reviewers for feedback on paper revisions.    </div>
</section>
  <section class="section no-spacing" id="Bibtex">
    <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
Our citation address here.
    </code></pre>
  </div>
</section>


<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->
</footer>

</body>
</html>